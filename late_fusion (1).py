# -*- coding: utf-8 -*-
"""late_fusion.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HTCBiZbtBZP2WUJrPSGTlw2BAPv8hxb2
"""

from google.colab import drive
drive.mount('/content/drive')

import os
import glob
import re 
import pandas as pd
from PIL import Image
from torch.utils.data import Dataset
import pandas as pd
import os
import torch
import torchvision.transforms as transforms
from torchvision import models
import numpy as np
import torch.nn as nn
import torch.optim as optim
import torchvision
from sklearn.metrics import classification_report
from sklearn import preprocessing
import datetime
import sklearn
import torch.nn.functional as F
import torchvision.transforms.functional as TF
import os
import shutil
import random
import cv2
import glob
from tqdm import tqdm
import itertools

"""### Data 
(16,224,224,3)のnumpy配列


"""

original_dir = 'drive/MyDrive/latefusion'

train_data_list = []
test_data_list = []
target_train = []
#train data
listofcats = ['brush_hair','clap','smoke','run']
for i,cat in enumerate(listofcats):
  path2cat = os.path.join(original_dir + '/' + 'train' + '/' + str(cat))
  listofdatas = os.listdir(path2cat)
  print(len(listofdatas))
  for data in listofdatas:
    path2data = os.path.join(original_dir + '/' + 'train' + '/' + str(cat) + '/' + str(data))
    d = np.load(path2data)
    #print(d.shape)
    train_data_list.append(d[:4])
  target_train.append([i]*len(listofdatas))

#test data
target_test = []
listofcats = os.listdir(original_dir +'/'+ 'test')
for j,cat in enumerate(listofcats):
  path2cat = os.path.join(original_dir + '/' + 'test' + '/' + str(cat))
  listofdatas = os.listdir(path2cat)
  print(len(listofdatas))
  for data in listofdatas:
    path2data = os.path.join(original_dir + '/' + 'test' + '/' + str(cat) + '/' + str(data))
    d = np.load(path2data)
    #print(d.shape)
    test_data_list.append(d[:4])
  target_test.append([j]*len(listofdatas))

import itertools
target_train = list(itertools.chain.from_iterable(target_train))
target_test = list(itertools.chain.from_iterable(target_test))

"""# データ数

|     |  brush_hair  |  clap  |  smoke  |  run  |
|---  |:----:     | :----:   | :--------:|:-------:|
|train|  160         |  196   |   174      |  348     |
|test |  41          |  49    |     44    |    87   |
"""

import itertools
print(len(target_train))
target_train = list(itertools.chain.from_iterable(target_train))
print(len(target_train))
print(len(target_test))
target_test = list(itertools.chain.from_iterable(target_test))
print(len(target_test))

"""#tesorに変換"""

# (T,W,H,C) -> (T,C,W,H)
train_data_list2 = []
for ts in train_data_list:
  #print(ts.shape)
  ts = torch.stack([TF.to_tensor(np.array(t)) for t in ts])
  #print(ts.shape)
  train_data_list2.append(ts)
X_train = torch.stack(train_data_list2)
print("X_train_size=",X_train.shape)
Y_train = torch.tensor([torch.from_numpy(np.array(i)) for i in target_train])
print("Y_train_size=",Y_train.shape)
test_data_list2 = []
for ts in test_data_list:
  #print(ts.shape)
  ts = torch.stack([TF.to_tensor(np.array(t)) for t in ts])
  #print(ts.shape)
  test_data_list2.append(ts)
X_test = torch.stack(test_data_list2)
print("X_test_size=",X_test.shape)
Y_test = torch.tensor([torch.from_numpy(np.array(i)) for i in target_test])
print("Y_test_size=",Y_test.shape)

"""# torchにload

"""

train_dataset = torch.utils.data.TensorDataset(X_train, Y_train)
train_loader = torch.utils.data.DataLoader(train_dataset,batch_size=32,shuffle=True)
test_dataset = torch.utils.data.TensorDataset(X_test, Y_test)
test_loader = torch.utils.data.DataLoader(test_dataset,batch_size=32,shuffle=True)

"""# CNN + FCL
CNNはResnetを使用
"""

cnn = models.resnet18(pretrained=True)
device=torch.device('cuda')
cnn.cuda()
for param in cnn.parameters():
    param.requires_grad = False

"""#### late fusion network

"""

class late_fusion(nn.Module):

  def __init__(self):
    super(late_fusion,self).__init__()
    #self.timestep = t
    self.timestep0 = cnn
    self.timestep1 = cnn
    self.timestep2 = cnn
    self.timestep3 = cnn
    self.timestep4 = cnn
    self.timestep5 = cnn
    self.timestep6 = cnn
    self.timestep7 = cnn

    self.fc1 = nn.Linear(4000,1024)
    self.dropout1 = torch.nn.Dropout2d(p=0.5)
    self.fc2 = nn.Linear(1024,512)
    self.dropout2 = torch.nn.Dropout(p=0.5) 
    self.fc3 = nn.Linear(512,64)
    self.dropout3 = torch.nn.Dropout(p=0.5) 
    self.fc4 = nn.Linear(64,4)
    self.relu = nn.ReLU()

  def forward(self,x):
    t0 = self.timestep0(x[:,0,:,:])
    t0 = t0.reshape(t0.size(0),-1)
    #print("t0",t0.shape)
    t1 = self.timestep1(x[:,1,:,:])
    t1 = t1.reshape(t1.size(0),-1)
    #print("t1",t1.shape)
    t2 = self.timestep2(x[:,2,:,:])
    t2 = t2.reshape(t2.size(0),-1)
    #print("t2",t2.shape)
    t3 = self.timestep3(x[:,3,:,:])
    t3 = t3.reshape(t3.size(0),-1)
    #print("t3",t3.shape)
    """t4 = self.timestep4(x[:,4,:,:])
    t4 = t4.reshape(t4.size(0),-1)
    #print("t4",t4.shape)
    t5 = self.timestep5(x[:,5,:,:])
    t5 = t5.reshape(t5.size(0),-1)
    #print("t5",t5.shape)
    t6 = self.timestep6(x[:,6,:,:])
    t6 = t6.reshape(t6.size(0),-1)
    #print("t6",t6.shape)
    t7 = self.timestep7(x[:,7,:,:])
    t7 = t7.reshape(t7.size(0),-1)"""
    #print("t7",t7.shape)
    
    x = torch.stack([t0,t1,t2,t3])
    #print("x",x.shape)
    x = x.permute(1,0,2)
    #print("x",x.shape)
    flatten = nn.Flatten()
    x = flatten(x)
    #print("x",x.shape)
    
    
    x = self.fc1(x)
    x = self.relu(x)
    x = self.dropout1(x)
    #print(x)
    x = self.fc2(x)
    x = self.relu(x)
    x = self.dropout2(x)
    #print(x)
    x = self.fc3(x)
    x = self.relu(x)
    x = self.dropout3(x)
    #print(x)
    x = self.fc4(x)
    #print(x)


    return x

device=torch.device('cuda')
net = late_fusion()
net.cuda()

for data,labels in train_loader:
  data, labels = data.to(device), labels.to(device)
  print(data.shape)
  output = net(data)
  print(output.shape)
  break

criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)

class EarlyStopping:
    """earlystoppingクラス"""

    def __init__(self, patience=5, verbose=False, path='checkpoint_model.pth'):
        """引数：最小値の非更新数カウンタ、表示設定、モデル格納path"""

        self.patience = patience    #設定ストップカウンタ
        self.verbose = verbose      #表示の有無
        self.counter = 0            #現在のカウンタ値
        self.best_score = None      #ベストスコア
        self.early_stop = False     #ストップフラグ
        self.val_loss_min = np.Inf   #前回のベストスコア記憶用
        self.path = path             #ベストモデル格納path

    def __call__(self, val_loss, model):
        """
        特殊(call)メソッド
        実際に学習ループ内で最小lossを更新したか否かを計算させる部分
        """
        score = -val_loss

        if self.best_score is None:  #1Epoch目の処理
            self.best_score = score   #1Epoch目はそのままベストスコアとして記録する
            self.checkpoint(val_loss, model)  #記録後にモデルを保存してスコア表示する
        elif score < self.best_score:  # ベストスコアを更新できなかった場合
            self.counter += 1   #ストップカウンタを+1
            if self.verbose:  #表示を有効にした場合は経過を表示
                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')  #現在のカウンタを表示する 
            if self.counter >= self.patience:  #設定カウントを上回ったらストップフラグをTrueに変更
                self.early_stop = True
        else:  #ベストスコアを更新した場合
            self.best_score = score  #ベストスコアを上書き
            self.checkpoint(val_loss, model)  #モデルを保存してスコア表示
            self.counter = 0  #ストップカウンタリセット

    def checkpoint(self, val_loss, model):
        '''ベストスコア更新時に実行されるチェックポイント関数'''
        if self.verbose:  #表示を有効にした場合は、前回のベストスコアからどれだけ更新したか？を表示
            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')
        torch.save(model.state_dict(), self.path)  #ベストモデルを指定したpathに保存
        self.val_loss_min = val_loss  #その時のlossを記録する

#loss,accuracyを格納
train_loss_list = []
train_acc_list = []
val_loss_list = []
val_acc_list = []

nb_epoch = 50
early_stopping = EarlyStopping(patience=30, verbose=True,path='drive/MyDrive/model/late_fusion.pth')
for epoch in range(nb_epoch):
    train_loss = 0
    train_acc = 0
    val_loss = 0
    val_acc = 0

    #train
    net.train()
    for i, (data, labels) in enumerate(train_loader):
      
      data, labels = data.to(device), labels.to(device)
      #print("labels",labels)
      optimizer.zero_grad()
      outputs = net(data)
      loss = criterion(outputs, labels)
      train_loss += loss.item()
      train_acc += (outputs.max(1)[1] == labels).sum().item()
      loss.backward()
      optimizer.step()

    avg_train_loss = train_loss / len(train_loader.dataset)
    avg_train_acc = train_acc / len(train_loader.dataset)

    train_loss_list.append(avg_train_loss)
    train_acc_list.append(avg_train_acc)
    print ('Epoch [{}/{}], loss: {loss:.4f} train_loss: {train_loss:.4f}, train_acc: {train_acc:.4f}' 
                   .format(epoch+1, nb_epoch, i+1, loss=avg_train_loss, train_loss=avg_train_loss, train_acc=avg_train_acc))
    #val
    net.eval()
    with torch.no_grad():
     for data, labels in test_loader:
      data = data.to(device)
      labels = labels.to(device)
      outputs = net(data)
      loss = criterion(outputs, labels)
      val_loss += loss.item()
      val_acc += (outputs.max(1)[1] == labels).sum().item()
    avg_val_loss = val_loss / len(test_loader.dataset)
    avg_val_acc = val_acc / len(test_loader.dataset)

    print ('Epoch [{}/{}], loss: {loss:.4f} val_loss: {val_loss:.4f}, val_acc: {val_acc:.4f}' 
                   .format(epoch+1, nb_epoch, i+1, loss=avg_train_loss, val_loss=avg_val_loss, val_acc=avg_val_acc))
    early_stopping(avg_val_loss, net)
    if early_stopping.early_stop:
            print("Early stopping")
            break
    val_loss_list.append(avg_val_loss)
    val_acc_list.append(avg_val_acc)

import matplotlib.pyplot as plt

plt.figure(figsize=(8,6))
plt.plot(train_loss_list,label='train', lw=3, c='b')
plt.plot(val_loss_list,label='test',lw=3,c = 'r')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('late_fusion')
plt.xticks(size=14)
plt.yticks(size=14)
plt.grid(lw=2)
plt.legend(fontsize=14)
plt.show()

plt.figure(figsize=(8,6))
plt.plot(train_acc_list,label='train', lw=3, c='b')
plt.plot(val_acc_list,label='test',lw=3,c = 'r')
plt.xlabel('Epoch')
plt.ylabel('accuracy')
plt.title('late_fusion')
plt.xticks(size=14)
plt.yticks(size=14)
plt.grid(lw=2)
plt.legend(fontsize=14)
plt.show()

